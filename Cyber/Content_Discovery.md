# Content Discovery â€” Cours complet (WebSec 0x04)

> **Cadre** : toutes les techniques et commandes ciâ€‘dessous doivent Ãªtre utilisÃ©es **uniquement** dans un environnement **autorisÃ©** (lab Holberton / machine cible / scope dÃ©fini).  
> **Objectif** : cartographier la surface dâ€™attaque Web en dÃ©couvrant des **endpoints**, **rÃ©pertoires**, **fichiers**, **API routes**, et fonctionnalitÃ©s **non liÃ©es** (unlinked / hidden content).

---

## Table des matiÃ¨res

1. [DÃ©finition : câ€™est quoi le *content discovery* ?](#dÃ©finition--cest-quoi-le-content-discovery-)
2. [Pourquoi câ€™est important ?](#pourquoi-cest-important-)
3. [Ce quâ€™on cherche : rÃ©pertoires, fichiers, endpoints, paramÃ¨tres](#ce-quon-cherche--rÃ©pertoires-fichiers-endpoints-paramÃ¨tres)
4. [MÃ©thodes de content discovery](#mÃ©thodes-de-content-discovery)
   - 4.1 [Passive discovery](#41-passive-discovery)
   - 4.2 [Active discovery](#42-active-discovery)
   - 4.3 [Forced browsing / directory bruteforce](#43-forced-browsing--directory-bruteforce)
   - 4.4 [Fuzzing : chemins, extensions, paramÃ¨tres](#44-fuzzing--chemins-extensions-paramÃ¨tres)
5. [Comprendre le directory bruteforcing](#comprendre-le-directory-bruteforcing)
6. [Wordlists : le carburant de lâ€™Ã©numÃ©ration](#wordlists--le-carburant-de-lÃ©numÃ©ration)
7. [Outils principaux](#outils-principaux)
   - 7.1 [Gobuster](#71-gobuster)
   - 7.2 [Feroxbuster](#72-feroxbuster)
   - 7.3 [DirBuster (GUI)](#73-dirbuster-gui)
   - 7.4 [Dirb](#74-dirb)
   - 7.5 [ffuf, wfuzz](#75-ffuf-wfuzz)
   - 7.6 [Nikto](#76-nikto)
8. [Burp Suite pour le content discovery](#burp-suite-pour-le-content-discovery)
9. [OWASP ZAP pour le content discovery](#owasp-zap-pour-le-content-discovery)
10. [GÃ©rer les piÃ¨ges : wildcard, faux positifs, WAF, rate-limit](#gÃ©rer-les-piÃ¨ges--wildcard-faux-positifs-waf-rate-limit)
11. [MÃ©thodologie â€œproâ€ (workflow)](#mÃ©thodologie-pro-workflow)
12. [Livrables & preuve (reporting)](#livrables--preuve-reporting)
13. [Exercices guidÃ©s (lab)](#exercices-guidÃ©s-lab)
14. [Cheat sheet](#cheat-sheet)
15. [RÃ©fÃ©rences](#rÃ©fÃ©rences)

---

## DÃ©finition : câ€™est quoi le *content discovery* ?

Le **content discovery** (ou **content enumeration**) est lâ€™ensemble des techniques visant Ã  **dÃ©couvrir** :
- des **ressources** accessibles via HTTP(S) (URL),
- **non visibles** dans la navigation â€œnormaleâ€ (pas de lien dans lâ€™UI),
- mais **prÃ©sentes** sur le serveur (rÃ©pertoires, fichiers, endpoints API, panels admin, backupsâ€¦).

On parle souvent de :
- **unlinked content** : contenu accessible mais non reliÃ© par des liens,
- **forced browsing** : tenter dâ€™accÃ©der directement Ã  des chemins â€œprobablesâ€,
- **predictable resource location** : les dÃ©veloppeurs utilisent souvent des noms prÃ©visibles (`/admin`, `/backup`, `/api/v1/â€¦`).

---

## Pourquoi câ€™est important ?

Sans discovery, tu testes une app â€œÃ  lâ€™aveugleâ€ :
- Tu ignores une partie de la surface dâ€™attaque â†’ tu rates des vulnÃ©rabilitÃ©s.
- Les zones sensibles sont souvent **cachÃ©es** (admin, debug, old versions, staging).
- Les fuites classiques sont des **fichiers oubliÃ©s** : `.bak`, `.old`, `.zip`, `.sql`, `.env`, `swagger.json`, `openapi.yaml`, `config.php~`, etc.

**Impact sÃ©curitÃ©** (exemples typiques) :
- accÃ¨s Ã  un **panel admin** non protÃ©gÃ©,
- exposition de **backups** ou **logs** contenant des secrets,
- endpoints API non documentÃ©s â†’ contournements auth,
- pages â€œlegacyâ€ vulnÃ©rables (XSS/SQLi/IDOR).

---

## Ce quâ€™on cherche : rÃ©pertoires, fichiers, endpoints, paramÃ¨tres

### 1) RÃ©pertoires
- `/admin/`, `/dashboard/`, `/internal/`, `/uploads/`, `/api/`, `/v1/`, `/static/`

### 2) Fichiers
- `robots.txt`, `sitemap.xml`, `swagger.json`
- `.env`, `.git/`, `.DS_Store`, `config.yml`
- backups : `index.php.bak`, `db.sql`, `site.zip`

### 3) Endpoints dynamiques / routes
- `/login`, `/register`, `/reset`, `/profile/edit`
- `/api/users`, `/api/orders`, `/graphql`

### 4) ParamÃ¨tres & fonctionnalitÃ©s â€œcachÃ©esâ€
- `?debug=true`, `?admin=1`, `?redirect=â€¦`
- paramÃ¨tres non documentÃ©s dans les formulaires
- champs JSON dans POST/PUT

---

## MÃ©thodes de content discovery

### 4.1 Passive discovery

But : collecter un maximum dâ€™indices **sans** bruteforce.

**Sources** :
- **HTML/JS** : regarder les routes appelÃ©es par le front (fetch/XHR).
- **Commentaires** : parfois des URLs cachÃ©es.
- **Headers** : `Server`, `X-Powered-By`, `Location`, etc.
- `robots.txt` & `sitemap.xml`
- **Historique** : outils, caches, archive (selon scope).

**Exemples dâ€™indices dans JS** :
- `/api/v2/users`
- `/admin/reports`
- `GET /debug/status`

> Astuce : en lab, lâ€™analyse du front (DevTools / Burp Proxy) donne souvent 30â€“60% de la cartographie â€œgratuitementâ€.

---

### 4.2 Active discovery

But : explorer activement via crawler/spider + navigation.

Techniques :
- Naviguer lâ€™app â€œcomme un userâ€
- Lancer un **crawler** (Burp / ZAP) â†’ construit une **site map**
- Tester manuellement des chemins â€œlogiquesâ€ :
  - `/admin`, `/administrator`, `/manage`
  - `/api`, `/graphql`, `/swagger`

---

### 4.3 Forced browsing / directory bruteforce

But : tester des milliers de chemins issus dâ€™une **wordlist**.

Principe :
- Pour chaque mot `w` dans la wordlist, le tool teste :
  - `GET /w` (ou `/w/`)
  - et/ou `GET /w.ext` (selon extensions)
- Il observe la rÃ©ponse :
  - code HTTP (200/301/302/401/403/500â€¦)
  - taille de rÃ©ponse
  - temps de rÃ©ponse
  - pattern (wildcard)

---

### 4.4 Fuzzing : chemins, extensions, paramÃ¨tres

**Fuzzing** = injecter une liste de payloads dans une partie variable dâ€™une requÃªte.

- **Path fuzzing** : `/FUZZ`
- **Extension fuzzing** : `index.FUZZ` (php, asp, aspx, jsâ€¦)
- **Param fuzzing** : `?FUZZ=value` ou `?param=FUZZ`
- **Body fuzzing** : JSON/POST

Exemple conceptuel :

```text
GET /api/v1/FUZZ HTTP/1.1
Host: target
```

OU

```text
GET /search?q=FUZZ HTTP/1.1
Host: target
```

---

## Comprendre le directory bruteforcing

### Comment Ã§a marche, concrÃ¨tement ?

1. Tu choisis une base URL : `http://TARGET/`
2. Tu choisis une wordlist : `common.txt`
3. Le tool â€œfabriqueâ€ des URLs :  
   - `/admin`, `/login`, `/uploads`, â€¦
4. Il envoie des requÃªtes HTTP en parallÃ¨le (threads)
5. Il filtre / affiche les hits significatifs

### Pourquoi on a des faux positifs ?

- Certaines apps renvoient **200** sur tout, avec une page â€œNot foundâ€ custom.
- Certains serveurs redirigent tout (302) vers `/login`.
- Certains WAF/CDN modifient les rÃ©ponses sous charge.

ğŸ‘‰ Dâ€™oÃ¹ lâ€™importance des filtres (codes, taille, regex) et de tests manuels.

---

## Wordlists : le carburant de lâ€™Ã©numÃ©ration

Une **wordlist** est une liste de mots (un par ligne) utilisÃ©e pour gÃ©nÃ©rer des chemins/paramÃ¨tres.

### OÃ¹ les trouver (Kali) ?
- `/usr/share/wordlists/`
- **SecLists** (souvent dans `/usr/share/seclists/` si installÃ©)

### Types utiles
- **small/common** : rapide, bon signal/bruit
- **medium** : meilleur coverage
- **large** : long, plus de bruit
- **extensions** : `.php`, `.html`, `.bak`, `.zip`, `.sql`, etc.
- **params** : `id`, `user`, `token`, `debug`, `redirect`, â€¦

### Construire une wordlist â€œintelligenteâ€
- Prendre les mots vus dans lâ€™app (menu, JS, API paths)
- Ajouter des variantes :
  - `admin`, `administrator`, `admin-panel`
  - `backup`, `backups`, `backup.zip`
- Ajouter des **technos** dÃ©tectÃ©es :
  - PHP â†’ `.php`, `.phps`
  - ASP.NET â†’ `.aspx`
  - Node â†’ `.js` (moins pour routes, plus pour assets)

---

## Outils principaux

> Tous ces outils font la mÃªme chose â€œau fondâ€ : **forcer des URLs** via une wordlist, avec des filtres.

### 7.1 Gobuster

**Gobuster** est un outil CLI rapide (Go) pour bruteâ€‘forcer :
- **rÃ©pertoires/fichiers** (mode `dir`)
- DNS (subdomains) et vhosts (hors scope ici, mais utile en recon)

#### Template minimal (dir)
```bash
gobuster dir -u http://TARGET -w /path/to/wordlist.txt
```

#### Avec extensions + threads + user-agent
```bash
gobuster dir -u http://TARGET -w /path/to/wordlist.txt -x php,txt,html,bak -t 50 -a "Mozilla/5.0"
```

#### Codes Ã  inclure/exclure
- inclure : `-s 200,204,301,302,307,401,403`
- exclure : `-b 404`

> Lecture rapide : 200 = OK, 301/302 = redirection (souvent intÃ©ressant), 401/403 = existe mais protÃ©gÃ© (aussi intÃ©ressant).

---

### 7.2 Feroxbuster

**Feroxbuster** (Rust) se distingue par le **rÃ©cursif** :
- dÃ©couvre un dossier `/admin/`
- puis bruteâ€‘force *dans* `/admin/` automatiquement (selon options)

#### Scan simple
```bash
feroxbuster -u http://TARGET -w /path/to/wordlist.txt
```

#### RÃ©cursion + profondeur + extensions + filtre
```bash
feroxbuster -u http://TARGET -w /path/to/wordlist.txt -x php,txt,html,bak -d 2 --status-codes 200 301 302 401 403
```

#### Utiliser un proxy (Burp)
```bash
feroxbuster -u http://TARGET -w /path/to/wordlist.txt --proxy http://127.0.0.1:8080
```

---

### 7.3 DirBuster (GUI)

**DirBuster** est un outil **GUI** (Java) historique OWASP.
- pratique pour visualiser, comparer des wordlists, rÃ©gler finement
- souvent plus lent que les tools modernes CLI, mais utile pÃ©dagogiquement

Workflow GUI :
1. target URL
2. wordlist
3. threads
4. extensions
5. run â†’ analyser rÃ©sultats

---

### 7.4 Dirb

**dirb** est â€œold schoolâ€ mais simple :
- rapide Ã  lancer
- wordlists basiques
- moins flexible que ferox/ffuf

Exemple :
```bash
dirb http://TARGET /path/to/wordlist.txt
```

---

### 7.5 ffuf, wfuzz

Ici on passe Ã  la logique â€œfuzzerâ€ :
- injection dans URL / param / body
- filtres avancÃ©s (status, taille, mots, regex)

#### ffuf (path fuzzing)
```bash
ffuf -u http://TARGET/FUZZ -w /path/to/wordlist.txt -mc 200,301,302,401,403
```

#### ffuf (extensions)
```bash
ffuf -u http://TARGET/FUZZ -w /path/to/wordlist.txt -e .php,.txt,.bak -mc 200,301,302,401,403
```

#### wfuzz (filtres 404/403)
```bash
wfuzz -c -z file,/path/to/wordlist.txt --hc 404 http://TARGET/FUZZ
```

> `--hc` = hide code (cache les rÃ©ponses 404).  
> Les filtres taille (`-fs`), mots (`-fw`) et lignes (`-fl`) sont tes meilleurs amis contre les wildcard.

---

### 7.6 Nikto

**Nikto** est un scanner web orientÃ© :
- fichiers â€œdangereuxâ€ connus
- mauvaises configs
- versions vulnÃ©rables (Ã  confirmer ensuite)

Ã‡a complÃ¨te le content discovery (pas un bruteforcer pur).

Exemple :
```bash
nikto -h http://TARGET
```

---

## Burp Suite pour le content discovery

Burp sert Ã  **cartographier** + **dÃ©couvrir** :
- tu proxifies ta navigation â†’ Burp construit une **Site map**
- tu lances la fonctionnalitÃ© **Discover content** (Engagement tools)
- tu peux ensuite envoyer les URLs dans Repeater/Intruder/Scanner (selon Ã©dition)

### Ã€ quoi Ã§a sert vraiment ?
- dÃ©couvrir du contenu non liÃ© que le crawler classique ne voit pas
- sâ€™appuyer sur tes requÃªtes rÃ©elles (auth, cookies, headers) â†’ plus efficace

### Workflow (concept)
1. Proxy ON â†’ browse app (login, sections)
2. Target â†’ Site map â†’ choisir host
3. Engagement tools â†’ Discover content
4. Configurer :
   - wordlist
   - types de requÃªtes
   - filtres
   - profondeur
5. Lancer, puis trier les hits

---

## OWASP ZAP pour le content discovery

ZAP offre plusieurs angles :

### 1) Spider / Crawl
Le **Spider** visite des URLs seed, extrait les liens, et explore rÃ©cursivement.

### 2) Forced Browse
â€œForced Browseâ€ tente des chemins depuis une wordlist (logique DirBuster), sans dÃ©pendre des liens.

### 3) Fuzzer
ZAP peut fuzz des paramÃ¨tres/requÃªtes (via lâ€™UI ou API), utile pour :
- parameter discovery
- variations de path
- tests sur JSON

---

## GÃ©rer les piÃ¨ges : wildcard, faux positifs, WAF, rate-limit

### Wildcard responses (le piÃ¨ge nÂ°1)
SymptÃ´me :
- `/thispagedoesnotexist` â†’ 200 OK avec une page â€œNot foundâ€
- ton bruteforce affiche des milliers de faux hits

Contreâ€‘mesures :
- comparer la **taille** des rÃ©ponses : un vrai `/admin` aura souvent une taille diffÃ©rente
- filtrer par **length/words/lines** (ffuf/wfuzz)
- tester un chemin alÃ©atoire pour â€œapprendreâ€ la signature du faux 200

### Redirections massives
Exemple :
- tout redirige vers `/login` (302)
- tu vois 302 partout

Contreâ€‘mesures :
- suivre la redirection et comparer la destination
- filtrer par `Location` si lâ€™outil le permet
- scanner en Ã©tant authentifiÃ© (cookies)

### Rate limiting / WAF
SymptÃ´mes :
- 429 Too Many Requests
- temps de rÃ©ponse explose
- blocage IP

Contreâ€‘mesures :
- rÃ©duire threads
- ajouter dÃ©lai
- varier User-Agent (pas magique, mais parfois)
- respecter le scope (en lab, te limite pas Ã  lâ€™absurde : tu veux apprendre, pas DOS)

---

## MÃ©thodologie â€œproâ€ (workflow)

### Vue dâ€™ensemble

```mermaid
flowchart TD
  A["DÃ©finir scope + base URL"] --> B["Passive discovery : robots.txt / sitemap.xml / JS / headers"]
  B --> C["Navigation + Proxy (Burp/ZAP) â†’ Site Map"]
  C --> D["Forced browsing : wordlist small â†’ medium â†’ targeted"]
  D --> E["RÃ©cursion : endpoints trouvÃ©s â†’ rescanner sous-dossiers"]
  E --> F["Parameter discovery + fuzzing sur zones clÃ©s"]
  F --> G["Triage : valider manuellement + classer par criticitÃ©"]
  G --> H["Reporting : preuves, endpoints, risques, reco"]
```

### Checklist rapide
- [ ] Aiâ€‘je fait un login et proxifiÃ© la session ?
- [ ] Aiâ€‘je rÃ©cupÃ©rÃ© robots/sitemap ?
- [ ] Aiâ€‘je analysÃ© le JS pour des routes API ?
- [ ] Aiâ€‘je lancÃ© un bruteforce â€œsmallâ€ (rapide) ?
- [ ] Aiâ€‘je adaptÃ© la wordlist Ã  la techno ?
- [ ] Aiâ€‘je gÃ©rÃ© wildcard et redirections ?
- [ ] Aiâ€‘je relancÃ© sur les dossiers trouvÃ©s (rÃ©cursif) ?
- [ ] Aiâ€‘je fait un mini fuzz de paramÃ¨tres ?

---

## Livrables & preuve (reporting)

Ce que tu dois Ãªtre capable de produire (mÃªme en projet Holberton) :
- **liste des endpoints** dÃ©couverts (avec mÃ©thode)
- **captures** (ou logs) montrant :
  - commande
  - rÃ©sultat (200/301/403â€¦)
- tri par catÃ©gories :
  - admin / auth / upload / api / debug / backups
- hypothÃ¨ses de risque :
  - â€œ403 sur /admin/ â†’ existe, vÃ©rifier contrÃ´le dâ€™accÃ¨sâ€
  - â€œ/backup.zip accessible â†’ fuite de code potentielleâ€
- recommandations :
  - retirer fichiers sensibles
  - fermer endpoints legacy
  - authent + least privilege
  - dÃ©sactiver directory listing
  - headers de sÃ©curitÃ©

---

## Exercices guidÃ©s (lab)

> Fais-les dans lâ€™ordre, et Ã©cris tes conclusions (1â€“2 lignes) aprÃ¨s chaque Ã©tape.

### Exo 1 â€” Passive discovery â€œpropreâ€
1. Trouver `robots.txt` et `sitemap.xml` si prÃ©sents
2. Ouvrir la page dâ€™accueil + inspecter le JS â†’ noter les routes

âœ… RÃ©sultat attendu : une liste dâ€™URLs candidates (5â€“20).

### Exo 2 â€” Bruteforce *small* (signal rapide)
1. Lancer un scan avec une wordlist **petite**
2. Garder seulement `200/301/302/401/403`

âœ… RÃ©sultat attendu : quelques hits pertinents + une idÃ©e du comportement 404.

### Exo 3 â€” DÃ©tection wildcard
1. Tester un chemin random : `/qzjzqzjzqzjz`
2. Comparer :
   - status code
   - taille
   - contenu

âœ… RÃ©sultat attendu : dÃ©cider si tu dois filtrer par taille/words.

### Exo 4 â€” RÃ©cursion
1. Si tu trouves `/admin/` ou `/api/`, rescanner ce sous-chemin
2. Noter les nouveaux endpoints

âœ… RÃ©sultat attendu : dÃ©couvrir des endpoints plus profonds.

### Exo 5 â€” Parameter discovery (simple)
1. Choisir un endpoint qui prend des paramÃ¨tres (ex: `/search`)
2. Fuzzer une liste de paramÃ¨tres (petite)

âœ… RÃ©sultat attendu : identifier un paramÃ¨tre â€œrÃ©elâ€ (diffÃ©rence de rÃ©ponse).

---

## Cheat sheet

### Codes HTTP utiles (discovery)
- **200** : existe (value)
- **301/302/307** : redirige (souvent value)
- **401** : existe mais nÃ©cessite auth
- **403** : existe mais interdit (trÃ¨s intÃ©ressant)
- **404** : absent (normal)
- **429** : rate-limit (ralentir)

### Heuristiques â€œrapid triageâ€
- `/admin`, `/manage`, `/console`, `/debug` â†’ zones sensibles
- `/uploads`, `/files`, `/static` â†’ risques dâ€™upload / leak
- `swagger`, `openapi`, `graphql` â†’ surface API importante
- `backup`, `.zip`, `.bak`, `.old`, `.sql` â†’ fuite potentielle

---

## Exigences projet (rappel Holberton / Kali)

### â€œScripts 1 ligneâ€
Si ton projet exige : `wc -l file` = **1**
- ton fichier doit contenir **une seule commande** (pas de shebang, pas de commentaires)
- exemple de fichier (une ligne) :

```bash
gobuster dir -u http://TARGET -w /usr/share/wordlists/dirb/common.txt -x php,txt,html -t 50 -s 200,301,302,401,403
```

### â€œFinir par une nouvelle ligneâ€
Beaucoup dâ€™outils Unix attendent une fin de ligne POSIX (EOF newline).  
Sans newline, certains parsers, diff, linters ou scripts de correction peuvent mal interprÃ©ter la derniÃ¨re ligne.

---

## RÃ©fÃ©rences

- OWASP Web Security Testing Guide (Information Gathering / Content review)
- PortSwigger Burp Suite docs (Discover content, Site map)
- OWASP ZAP docs (Spider, Forced Browse)
- Kali Tools docs (DirBuster, Feroxbuster)
- Docs GitHub des outils (Gobuster, Feroxbuster, ffuf, nikto)

> Note : le terme **â€œsfuzzâ€** est ambigu. Dans le contexte web, les outils les plus standards pour fuzzing/discovery sont **ffuf** et **wfuzz**. â€œSFuzzâ€ existe aussi comme fuzzer acadÃ©mique (autre contexte), donc vÃ©rifie ce que ton module Holberton vise exactement.
